{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from LookGenerator.datasets.utils import load_image\n",
    "from LookGenerator.datasets.person_segmentation_dataset import PersonSegmentationDataset, PersonSegmentationDatasetMultichannel\n",
    "from LookGenerator.networks.segmentation import UNet, train_unet\n",
    "from LookGenerator.networks.utils import load_model\n",
    "import LookGenerator.datasets.transforms as custom_transforms\n",
    "import albumentations\n",
    "from LookGenerator.networks_training.utils import check_path_and_creat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform_input = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.RandomAffine(scale=(0.8, 1), degrees=(-90,90), fill = 0.9),\n",
    "    transforms.ColorJitter(brightness=(0.5, 1), contrast=(0.4,1),  hue=(0, 0.3)),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.25, 0.25, 0.25]\n",
    "    )\n",
    "])\n",
    "\n",
    "transform_output = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.MinMaxScale(),\n",
    "    custom_transforms.ThresholdTransform(threshold=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size_train = 1\n",
    "batch_size_val = 16\n",
    "pin_memory = True\n",
    "num_workers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(11647, 11647)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = PersonSegmentationDatasetMultichannel(r'C:\\Users\\Даша\\кто\\мусор\\zalando-hd-resized\\train',\n",
    "    #r\"C:\\Users\\DenisovDmitrii\\Desktop\\trainData\",\n",
    "                                                      transform_input=transform_input,\n",
    "                                                      transform_output=transform_output)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True, pin_memory=pin_memory, num_workers=num_workers)\n",
    "(len(train_dataset), len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(2032, 127)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset = PersonSegmentationDatasetMultichannel(r'C:\\Users\\Даша\\кто\\мусор\\zalando-hd-resized\\test')#r\"C:\\Users\\DenisovDmitrii\\Desktop\\valData\")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size_val, shuffle=False, pin_memory=pin_memory, num_workers=num_workers)\n",
    "(len(val_dataset), len(val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test load train_dataloader. and val."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    plt.imshow(X.detach().numpy()[0,0,:,:])\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Метки классов на изображении:\n",
    "\n",
    "1. Левое лицо                       248,251,14\n",
    "2. Правое лицо                      251,235,25\n",
    "3. Туловище                         20,80,194\n",
    "4. Внешняя верхняя левая рука       190,189,96\n",
    "5. Внешняя верхняя правая рука      215,187,88\n",
    "6. Внешняя нижняя левая рука        252,206,48\n",
    "7. Внешняя нижняя правая рука       250,220,36\n",
    "8. Внутренняя верхняя левая рука    145,191,116\n",
    "9. Внутренняя верхняя правая рука   170,190,105\n",
    "10. Внетренняя нижняя левая рука     228,191,74\n",
    "11. Внутренняя нижняя правая рука    240,198,60\n",
    "12. Левая кисть                      8,110,221\n",
    "13. Правая кисть                     4,98,224\n",
    "14. Левая нога                       22,173,184\n",
    "15. Правая нога                      6,166,198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model = UNet(in_channels=3, out_channels = 15)\n",
    "#model = load_model(model, r'C:\\Users\\DenisovDmitrii\\Desktop\\segmentation_weits\\session12\\asd.pt')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(\"start time\", now.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "save_directory = \"C:\\\\Users\\\\DenisovDmitrii\\\\Desktop\\\\segmentation_weits\\\\session36\"\n",
    "check_path_and_creat(save_directory)\n",
    "train_history, val_history = train_unet(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    optimizer,\n",
    "    device=device,\n",
    "    epoch_num=20,\n",
    "    save_directory= save_directory\n",
    ")\n",
    "old = now\n",
    "now = datetime.datetime.now()\n",
    "print(\"end time\", now.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "print(\"delta\", now - old)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = load_model(model, r'C:\\Users\\Даша\\PycharmProjects\\SMBackEnd\\LookGenerator\\weights\\unet_epoch_0_0.0161572862694324.pt')\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dir = r\"\"\n",
    "test_folder = \"\"\n",
    "save_masks_dir = r\"\"\n",
    "list_files = os.listdir(test_dir)\n",
    "images = [file.split('.') for file in list_files]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    print(image)\n",
    "    img = load_image(test_dir, test_folder, image, '.jpg')\n",
    "    img_to_model = prepare_image_for_model(img, transform_input)\n",
    "    modelled = model(img_to_model)\n",
    "    mask = to_array_from_model_bin(modelled)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1,2,0)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(mask)\n",
    "\n",
    "    Image.fromarray(mask, 'L').save(save_masks_dir + image + '.png')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
