{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from LookGenerator.datasets.utils import load_image, prepare_image_for_model, to_array_from_model_bin\n",
    "from LookGenerator.datasets.person_segmentation_dataset import PersonSegmentationDataset, PersonSegmentationDatasetMultichannel\n",
    "from LookGenerator.networks.segmentation import UNet, train_unet\n",
    "from LookGenerator.networks.utils import load_model\n",
    "import LookGenerator.datasets.transforms as custom_transforms\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform_input = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.25, 0.25, 0.25]\n",
    "    )\n",
    "])\n",
    "\n",
    "transform_output = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.MinMaxScale(),\n",
    "    custom_transforms.ThresholdTransform(threshold=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size_train = 1\n",
    "batch_size_val = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "transform_train = albumentations.Compose([\n",
    "        albumentations.Resize(height=256, width=192),\n",
    "        albumentations.RandomBrightnessContrast(brightness_limit=(0.1,0.3), contrast_limit=(0.2,0.7), p =0.2),\n",
    "        albumentations.Equalize(p = 0.2),\n",
    "        albumentations.GaussNoise(p = 0.2),\n",
    "        albumentations.Affine(translate_percent=0.1, scale=(0.8, 1), rotate=(-90,90), p=0.2),\n",
    "        albumentations.Normalize(mean = (0.5, 0.5, 0.5), std = (0.25, 0.25, 0.25)),\n",
    "    ])\n",
    "\n",
    "transform_valid = albumentations.Compose([\n",
    "        albumentations.Resize(height=256, width=192),\n",
    "        albumentations.Normalize(mean = (0.5, 0.5, 0.5), std = (0.25, 0.25, 0.25)),\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(70, 70)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = PersonSegmentationDatasetMultichannel(r\"C:\\Users\\Даша\\кто\\мусор\\zalando-hd-resized\\wer\", augment=transform_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "(len(train_dataset), len(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 192])\n",
      "torch.Size([1, 15, 256, 192])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(2937, 92)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = PersonSegmentationDataset(\"C:\\\\Users\\\\DenisovDmitrii\\\\Desktop\\\\train\", augment=transform_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "(len(train_dataset), len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(936, 59)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset = PersonSegmentationDataset(\"C:\\\\Users\\\\DenisovDmitrii\\\\Desktop\\\\test\", augment=transform_valid)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size_val, shuffle=False)\n",
    "(len(val_dataset), len(val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test load train_dataloader. and val."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    plt.imshow(X.detach().numpy()[0,0,:,:], cmap = 'binary')\n",
    "    plt.show()\n",
    "    plt.imshow(y.detach().numpy()[0,0,:,:], cmap = 'binary')\n",
    "    plt.show()\n",
    "    # modelled_img = to_array_from_model_bin_transpose(transform_output(X.detach()))\n",
    "    # plt.imshow(modelled_img,cmap = 'binary')\n",
    "    # plt.show()\n",
    "    # modelled_img = to_array_from_model_bin_transpose(transform_output(y.detach()))\n",
    "    # plt.imshow(modelled_img,cmap = 'binary')\n",
    "    # plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Метки классов на изображении:\n",
    "\n",
    "1. Левое лицо                       248,251,14\n",
    "2. Правое лицо                      251,235,25\n",
    "3. Туловище                         20,80,194\n",
    "4. Внешняя верхняя левая рука       190,189,96\n",
    "5. Внешняя верхняя правая рука      215,187,88\n",
    "6. Внешняя нижняя левая рука        252,206,48\n",
    "7. Внешняя нижняя правая рука       250,220,36\n",
    "8. Внутренняя верхняя левая рука    145,191,116\n",
    "9. Внутренняя верхняя правая рука   170,190,105\n",
    "10. Внетренняя нижняя левая рука     228,191,74\n",
    "11. Внутренняя нижняя правая рука    240,198,60\n",
    "12. Левая кисть                      8,110,221\n",
    "13. Правая кисть                     4,98,224\n",
    "14. Левая нога                       22,173,184\n",
    "15. Правая нога                      6,166,198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model = UNet(in_channels=3, out_channels = 1)\n",
    "#model = load_model(model, r'C:\\Users\\DenisovDmitrii\\Desktop\\segmentation_weits\\session12\\asd.pt')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(\"start time\", now.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "\n",
    "train_history, val_history = train_unet(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    optimizer,\n",
    "    device=device,\n",
    "    epoch_num=30,\n",
    "    save_directory=\"C:\\\\Users\\\\DenisovDmitrii\\\\Desktop\\\\segmentation_weits\\\\session31\"\n",
    ")\n",
    "old = now\n",
    "now = datetime.datetime.now()\n",
    "print(\"end time\", now.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "print(\"delta\", now - old)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = load_model(model, r'C:\\Users\\Даша\\PycharmProjects\\SMBackEnd\\LookGenerator\\weights\\unet_epoch_0_0.0161572862694324.pt')\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dir = r\"\"\n",
    "test_folder = \"\"\n",
    "save_masks_dir = r\"\"\n",
    "list_files = os.listdir(test_dir)\n",
    "images = [file.split('.') for file in list_files]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    print(image)\n",
    "    img = load_image(test_dir, test_folder, image, '.jpg')\n",
    "    img_to_model = prepare_image_for_model(img, transform_input)\n",
    "    modelled = model(img_to_model)\n",
    "    mask = to_array_from_model_bin(modelled)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1,2,0)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(mask)\n",
    "\n",
    "    Image.fromarray(mask, 'L').save(save_masks_dir + image + '.png')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
