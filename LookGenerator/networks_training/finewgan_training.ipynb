{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from LookGenerator.networks.losses import WassersteinLoss, GradientPenalty, FineGANLoss\n",
    "from LookGenerator.datasets.encoder_decoder_datasets import EncoderDecoderDataset\n",
    "from LookGenerator.networks.fine_gan import *\n",
    "from LookGenerator.networks_training.utils import check_path_and_creat\n",
    "import LookGenerator.datasets.transforms as custom_transforms\n",
    "from LookGenerator.networks.utils import get_num_digits, save_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:39.440543Z",
     "end_time": "2023-04-11T00:03:40.855843Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "transform_input = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_real = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.MinMaxScale()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:40.856847Z",
     "end_time": "2023-04-11T00:03:40.859611Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "batch_size_train = 32\n",
    "pin_memory = True\n",
    "num_workers = 4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:40.857548Z",
     "end_time": "2023-04-11T00:03:40.873718Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_dataset = EncoderDecoderDataset(\n",
    "    image_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\train\",\n",
    "    transform_human=transform_input,\n",
    "    transform_clothes=transform_input,\n",
    "    transform_human_restored=transform_real\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:40.873718Z",
     "end_time": "2023-04-11T00:03:40.901176Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size_train, shuffle=True, pin_memory=pin_memory, num_workers=num_workers\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:40.903182Z",
     "end_time": "2023-04-11T00:03:40.905187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:40.905187Z",
     "end_time": "2023-04-11T00:03:40.911412Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def _epoch_string(epoch, epoch_num):\n",
    "    num_digits_epoch_num = get_num_digits(epoch_num)\n",
    "    num_digits_epoch = get_num_digits(epoch)\n",
    "\n",
    "    epoch_string = \"0\"*(num_digits_epoch_num - num_digits_epoch) + str(epoch)\n",
    "    return epoch_string\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:40.911412Z",
     "end_time": "2023-04-11T00:03:40.917166Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def fit(model, criterion, gradient_penalty, train_dl, device, epochs, g_lr, d_lr,\n",
    "        save_directory_generator, save_directory_discriminator, save_step=1):\n",
    "    model[\"discriminator\"].train()\n",
    "    model[\"generator\"].train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Losses & scores\n",
    "    losses_g = []\n",
    "    losses_d = []\n",
    "    real_scores = []\n",
    "    fake_scores = []\n",
    "\n",
    "    # Create optimizers\n",
    "    optimizer = {\n",
    "        \"discriminator\": torch.optim.Adam(model[\"discriminator\"].parameters(),\n",
    "                                          lr=d_lr, betas=(0.5, 0.999)),\n",
    "        \"generator\": torch.optim.Adam(model[\"generator\"].parameters(),\n",
    "                                      lr=g_lr, betas=(0.5, 0.999))\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss_d_per_epoch = []\n",
    "        loss_g_per_epoch = []\n",
    "        real_score_per_epoch = []\n",
    "        fake_score_per_epoch = []\n",
    "        model['discriminator'] = model['discriminator'].to(device)\n",
    "        model['generator'] = model['generator'].to(device)\n",
    "        for iteration, (input_images, real_images) in enumerate(tqdm(train_dl), 0):\n",
    "            input_images = input_images.to(device)\n",
    "            real_images = real_images.to(device)\n",
    "            # Train discriminator\n",
    "            # Clear discriminator gradients\n",
    "            optimizer[\"discriminator\"].zero_grad()\n",
    "\n",
    "            real_images = real_images.to(device)\n",
    "\n",
    "            # Pass real images through discriminator\n",
    "            real_preds = model[\"discriminator\"](real_images)\n",
    "            real_targets = torch.ones(real_images.shape[0], 1, device=device)\n",
    "            real_loss = criterion[\"discriminator\"](real_preds, real_targets)\n",
    "            cur_real_score = torch.mean(real_preds).item()\n",
    "\n",
    "            # Generate fake images\n",
    "            fake_images = model[\"generator\"](input_images)\n",
    "\n",
    "            # Pass fake images through discriminator\n",
    "            fake_targets = torch.ones(fake_images.shape[0], 1, device=device)\n",
    "            fake_preds = model[\"discriminator\"](fake_images)\n",
    "            fake_loss = criterion[\"discriminator\"](fake_preds, fake_targets)\n",
    "            cur_fake_score = torch.mean(fake_preds).item()\n",
    "            gp = gradient_penalty(model[\"discriminator\"], real_images, fake_images, device)\n",
    "\n",
    "            real_score_per_epoch.append(cur_real_score)\n",
    "            fake_score_per_epoch.append(cur_fake_score)\n",
    "\n",
    "            # Update discriminator weights\n",
    "            loss_d = real_loss + fake_loss + 10.0 * gp\n",
    "            loss_d.backward()\n",
    "            optimizer[\"discriminator\"].step()\n",
    "            loss_d_per_epoch.append(loss_d.item())\n",
    "\n",
    "            # Train generator\n",
    "            if iteration % 5 == 0:\n",
    "            # Clear generator gradients\n",
    "                optimizer[\"generator\"].zero_grad()\n",
    "\n",
    "                # Generate fake images\n",
    "                fake_images = model[\"generator\"](input_images)\n",
    "\n",
    "                # Try to fool the discriminator\n",
    "                preds = model[\"discriminator\"](fake_images)\n",
    "                targets = torch.ones(real_images.shape[0], 1, device=device)\n",
    "                loss_g = criterion[\"generator\"](preds, targets, fake_images, real_images)\n",
    "\n",
    "                # Update generator weights\n",
    "                loss_g.backward()\n",
    "                optimizer[\"generator\"].step()\n",
    "                loss_g_per_epoch.append(loss_g.item())\n",
    "\n",
    "                losses_g.append(np.mean(loss_g_per_epoch))\n",
    "\n",
    "        # Record losses & scores\n",
    "        losses_d.append(np.mean(loss_d_per_epoch))\n",
    "        real_scores.append(np.mean(real_score_per_epoch))\n",
    "        fake_scores.append(np.mean(fake_score_per_epoch))\n",
    "\n",
    "        # Log losses & scores (last batch)\n",
    "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "            epoch+1, epochs,\n",
    "            losses_g[-1], losses_d[-1], real_scores[-1], fake_scores[-1])\n",
    "        )\n",
    "\n",
    "        if (epoch + 1) % save_step == 0:\n",
    "            save_model(\n",
    "                model[\"discriminator\"].to('cpu'),\n",
    "                path=f\"{save_directory_discriminator}\\\\discriminator_epoch_{_epoch_string(epoch, epochs)}.pt\"\n",
    "            )\n",
    "            save_model(\n",
    "                model[\"generator\"].to('cpu'),\n",
    "                path=f\"{save_directory_generator}\\\\generator_epoch_{_epoch_string(epoch, epochs)}.pt\"\n",
    "            )\n",
    "\n",
    "    return losses_g, losses_d, real_scores, fake_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:40.918161Z",
     "end_time": "2023-04-11T00:03:40.929480Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory_generator=r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\encoderGAN\\weights\\gen\\session2\"\n",
    "save_directory_discriminator=r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\encoderGAN\\weights\\discr\\session2\"\n",
    "check_path_and_creat(save_directory_generator)\n",
    "check_path_and_creat(save_directory_discriminator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:40.925466Z",
     "end_time": "2023-04-11T00:03:40.945536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = EncoderDecoderGenerator(in_channels=6)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "wasserstein_criterion = WassersteinLoss()\n",
    "gradient_penalty = GradientPenalty(discriminator, device=device)\n",
    "\n",
    "criterion_generator = FineGANLoss(\n",
    "    adversarial_criterion=wasserstein_criterion, adv_loss_weight=0.25,\n",
    "    l1_criterion=True, l1_loss_weight=4,\n",
    "    perceptual=True, perceptual_loss_weight=1, device=device\n",
    ")\n",
    "criterion_discriminator = WassersteinLoss()\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:40.933495Z",
     "end_time": "2023-04-11T00:03:41.684020Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"discriminator\": discriminator.to(device),\n",
    "    \"generator\": generator.to(device)\n",
    "}\n",
    "\n",
    "criterion = {\n",
    "    \"discriminator\": criterion_discriminator.to(device),\n",
    "    \"generator\": criterion_generator.to(device)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:41.681010Z",
     "end_time": "2023-04-11T00:03:41.695059Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = fit(model=model,\n",
    "              criterion=criterion,\n",
    "              gradient_penalty=gradient_penalty,\n",
    "              train_dl=train_dataloader,\n",
    "              device=device,\n",
    "              epochs=10,\n",
    "              g_lr=0.0001,\n",
    "              d_lr=0.0001,\n",
    "              save_directory_generator=save_directory_generator,\n",
    "              save_directory_discriminator=save_directory_discriminator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:03:41.695059Z",
     "end_time": "2023-04-11T01:02:58.180449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "test_dataset = EncoderDecoderDataset(\n",
    "    image_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\val\",\n",
    "    transform_human=transform_input,\n",
    "    transform_clothes=transform_input,\n",
    "    transform_human_restored=transform_real\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T01:02:58.188477Z",
     "end_time": "2023-04-11T01:02:58.193506Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator.to('cpu')\n",
    "discriminator.to('cpu')\n",
    "image, real_image = test_dataset[2]\n",
    "image = image.unsqueeze(0)\n",
    "#print(image)\n",
    "print(image.shape)\n",
    "image = generator(image)\n",
    "imaged = discriminator(image)\n",
    "image = transforms.ToPILImage()(image[0, :, :, :])\n",
    "image.show()\n",
    "print(imaged)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T01:02:58.197201Z",
     "end_time": "2023-04-11T01:03:01.725081Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
