{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from LookGenerator.networks.losses import WassersteinLoss, GradientPenalty, FineGANLoss\n",
    "from LookGenerator.datasets.encoder_decoder_datasets import EncoderDecoderDataset\n",
    "from LookGenerator.networks.fine_gan import *\n",
    "from LookGenerator.networks.clothes_feature_extractor import ClothAutoencoder\n",
    "from LookGenerator.networks.trainer import WGANGPTrainer\n",
    "from LookGenerator.networks_training.utils import check_path_and_creat\n",
    "from LookGenerator.networks.utils import get_num_digits, save_model, load_model\n",
    "import LookGenerator.datasets.transforms as custom_transforms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:04.190704500Z",
     "start_time": "2023-06-02T12:35:02.894270300Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "transform_input = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_real = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.MinMaxScale()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:04.193318400Z",
     "start_time": "2023-06-02T12:35:04.191708300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "batch_size_train = 24\n",
    "pin_memory = True\n",
    "num_workers = 6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:04.199038400Z",
     "start_time": "2023-06-02T12:35:04.193318400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_dataset = EncoderDecoderDataset(\n",
    "    image_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoderNew\\train\",\n",
    "    transform_human=transform_input,\n",
    "    transform_clothes=transform_input,\n",
    "    transform_human_restored=transform_real\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:04.217832100Z",
     "start_time": "2023-06-02T12:35:04.200034300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size_train, shuffle=True, pin_memory=pin_memory, num_workers=num_workers\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:04.219999400Z",
     "start_time": "2023-06-02T12:35:04.218836200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:04.227830100Z",
     "start_time": "2023-06-02T12:35:04.220994800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# def _epoch_string(epoch, epoch_num):\n",
    "#     num_digits_epoch_num = get_num_digits(epoch_num)\n",
    "#     num_digits_epoch = get_num_digits(epoch)\n",
    "#\n",
    "#     epoch_string = \"0\"*(num_digits_epoch_num - num_digits_epoch) + str(epoch)\n",
    "#     return epoch_string\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:32:51.865443400Z",
     "start_time": "2023-06-02T12:32:51.860238200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# def fit(model, criterion, gradient_penalty, train_dl, device, epochs, g_lr, d_lr,\n",
    "#         save_directory_generator, save_directory_discriminator, save_step=1):\n",
    "#     model[\"discriminator\"].train()\n",
    "#     model[\"generator\"].train()\n",
    "#     torch.cuda.empty_cache()\n",
    "#\n",
    "#     # Losses & scores\n",
    "#     losses_g = []\n",
    "#     losses_d = []\n",
    "#     real_scores = []\n",
    "#     fake_scores = []\n",
    "#\n",
    "#     # Create optimizers\n",
    "#     optimizer = {\n",
    "#         \"discriminator\": torch.optim.Adam(model[\"discriminator\"].parameters(),\n",
    "#                                           lr=d_lr, betas=(0.5, 0.999)),\n",
    "#         \"generator\": torch.optim.Adam(model[\"generator\"].parameters(),\n",
    "#                                       lr=g_lr, betas=(0.5, 0.999))\n",
    "#     }\n",
    "#\n",
    "#     for epoch in range(epochs):\n",
    "#         loss_d_per_epoch = []\n",
    "#         loss_g_per_epoch = []\n",
    "#         real_score_per_epoch = []\n",
    "#         fake_score_per_epoch = []\n",
    "#         model['discriminator'] = model['discriminator'].to(device)\n",
    "#         model['generator'] = model['generator'].to(device)\n",
    "#         for iteration, (input_images, real_images) in enumerate(tqdm(train_dl), 0):\n",
    "#             input_images = input_images.to(device)\n",
    "#             real_images = real_images.to(device)\n",
    "#             # Train discriminator\n",
    "#             # Clear discriminator gradients\n",
    "#             optimizer[\"discriminator\"].zero_grad()\n",
    "#\n",
    "#             real_images = real_images.to(device)\n",
    "#\n",
    "#             # Pass real images through discriminator\n",
    "#             real_preds = model[\"discriminator\"](real_images)\n",
    "#             real_targets = torch.ones(real_images.shape[0], 1, device=device)\n",
    "#             real_loss = criterion[\"discriminator\"](real_preds, real_targets)\n",
    "#             cur_real_score = torch.mean(real_preds).item()\n",
    "#\n",
    "#             # Generate fake images\n",
    "#             fake_images = model[\"generator\"](input_images)\n",
    "#\n",
    "#             # Pass fake images through discriminator\n",
    "#             fake_targets = torch.ones(fake_images.shape[0], 1, device=device)\n",
    "#             fake_preds = model[\"discriminator\"](fake_images)\n",
    "#             fake_loss = criterion[\"discriminator\"](fake_preds, fake_targets)\n",
    "#             cur_fake_score = torch.mean(fake_preds).item()\n",
    "#             gp = gradient_penalty(model[\"discriminator\"], real_images, fake_images, device)\n",
    "#\n",
    "#             real_score_per_epoch.append(cur_real_score)\n",
    "#             fake_score_per_epoch.append(cur_fake_score)\n",
    "#\n",
    "#             # Update discriminator weights\n",
    "#             loss_d = real_loss + fake_loss + 10.0 * gp\n",
    "#             loss_d.backward()\n",
    "#             optimizer[\"discriminator\"].step()\n",
    "#             loss_d_per_epoch.append(loss_d.item())\n",
    "#\n",
    "#             # Train generator\n",
    "#             if iteration % 5 == 0:\n",
    "#             # Clear generator gradients\n",
    "#                 optimizer[\"generator\"].zero_grad()\n",
    "#\n",
    "#                 # Generate fake images\n",
    "#                 fake_images = model[\"generator\"](input_images)\n",
    "#\n",
    "#                 # Try to fool the discriminator\n",
    "#                 preds = model[\"discriminator\"](fake_images)\n",
    "#                 targets = torch.ones(real_images.shape[0], 1, device=device)\n",
    "#                 loss_g = criterion[\"generator\"](preds, targets, fake_images, real_images)\n",
    "#\n",
    "#                 # Update generator weights\n",
    "#                 loss_g.backward()\n",
    "#                 optimizer[\"generator\"].step()\n",
    "#                 loss_g_per_epoch.append(loss_g.item())\n",
    "#\n",
    "#                 losses_g.append(np.mean(loss_g_per_epoch))\n",
    "#\n",
    "#         # Record losses & scores\n",
    "#         losses_d.append(np.mean(loss_d_per_epoch))\n",
    "#         real_scores.append(np.mean(real_score_per_epoch))\n",
    "#         fake_scores.append(np.mean(fake_score_per_epoch))\n",
    "#\n",
    "#         # Log losses & scores (last batch)\n",
    "#         print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "#             epoch+1, epochs,\n",
    "#             losses_g[-1], losses_d[-1], real_scores[-1], fake_scores[-1])\n",
    "#         )\n",
    "#\n",
    "#         if (epoch + 1) % save_step == 0:\n",
    "#             save_model(\n",
    "#                 model[\"discriminator\"].to('cpu'),\n",
    "#                 path=f\"{save_directory_discriminator}\\\\discriminator_epoch_{_epoch_string(epoch, epochs)}.pt\"\n",
    "#             )\n",
    "#             save_model(\n",
    "#                 model[\"generator\"].to('cpu'),\n",
    "#                 path=f\"{save_directory_generator}\\\\generator_epoch_{_epoch_string(epoch, epochs)}.pt\"\n",
    "#             )\n",
    "#\n",
    "#     return losses_g, losses_d, real_scores, fake_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:32:51.927256300Z",
     "start_time": "2023-06-02T12:32:51.866439400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory = r'C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\encoderGAN\\weights\\testBaseParam'\n",
    "check_path_and_creat(save_directory)\n",
    "save_directory_generator = os.path.join(save_directory, 'gen')\n",
    "save_directory_discriminator = os.path.join(save_directory, 'discr')\n",
    "check_path_and_creat(save_directory_generator)\n",
    "check_path_and_creat(save_directory_discriminator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:04.236861400Z",
     "start_time": "2023-06-02T12:35:04.227830100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "clothes_feature_extractor = ClothAutoencoder(\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    features=(8, 16, 32, 64),\n",
    "    latent_dim_size=128,\n",
    "    encoder_activation_func=nn.LeakyReLU(),\n",
    "    decoder_activation_func=nn.ReLU()\n",
    ")\n",
    "clothes_feature_extractor = load_model(clothes_feature_extractor, r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\autoDegradation\\weights\\testClothes_L1Loss_4features\\epoch_39.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:04.305143500Z",
     "start_time": "2023-06-02T12:35:04.236861400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DenisovDmitrii\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DenisovDmitrii\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "generator = EncoderDecoderGenerator(clothes_feature_extractor=clothes_feature_extractor, in_channels=3, out_channels=3, final_activation_func=nn.Sigmoid())\n",
    "discriminator = Discriminator()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "wasserstein_criterion = WassersteinLoss()\n",
    "gradient_penalty = GradientPenalty(discriminator, device=device)\n",
    "\n",
    "criterion_generator = FineGANLoss(\n",
    "    adversarial_criterion=wasserstein_criterion, adv_loss_weight=0.25,\n",
    "    l1_criterion=True, l1_loss_weight=4,\n",
    "    perceptual=True, perceptual_loss_weight=1, device=device\n",
    ")\n",
    "criterion_discriminator = WassersteinLoss()\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:05.196530400Z",
     "start_time": "2023-06-02T12:35:04.305143500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "optimizer_generator = torch.optim.Adam(params=generator.parameters(), lr=0.001)\n",
    "optimizer_discriminator = torch.optim.Adam(params=discriminator.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:05.378805800Z",
     "start_time": "2023-06-02T12:35:05.371895700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"discriminator\": discriminator.to(device),\n",
    "    \"generator\": generator.to(device)\n",
    "}\n",
    "\n",
    "criterion = {\n",
    "    \"discriminator\": criterion_discriminator.to(device),\n",
    "    \"generator\": criterion_generator.to(device)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:26.494804500Z",
     "start_time": "2023-06-02T12:35:26.488911700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "trainer = WGANGPTrainer(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    optimizer_generator=optimizer_generator,\n",
    "    optimizer_discriminator=optimizer_discriminator,\n",
    "    criterion_generator=criterion_generator,\n",
    "    criterion_discriminator=criterion_discriminator,\n",
    "    gradient_penalty=gradient_penalty,\n",
    "    gp_weight=0.2,\n",
    "    save_step=1,\n",
    "    save_directory_discriminator=save_directory_discriminator,\n",
    "    save_directory_generator=save_directory_generator,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:27.395575100Z",
     "start_time": "2023-06-02T12:35:27.389412500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# history = fit(model=model,\n",
    "#               criterion=criterion,\n",
    "#               gradient_penalty=gradient_penalty,\n",
    "#               train_dl=train_dataloader,\n",
    "#               device=device,\n",
    "#               epochs=10,\n",
    "#               g_lr=0.0001,\n",
    "#               d_lr=0.0001,\n",
    "#               save_directory_generator=save_directory_generator,\n",
    "#               save_directory_discriminator=save_directory_discriminator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:28.786649800Z",
     "start_time": "2023-06-02T12:35:28.780956100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "epoch_num = 20"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T12:35:29.121844600Z",
     "start_time": "2023-06-02T12:35:29.115194600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 02-06-2023 15:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/486 [00:00<?, ?it/s]C:\\Users\\DenisovDmitrii\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 486/486 [05:53<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 of 19, discriminator loss: 0.00251\n",
      "Epoch 0 of 19, generator loss: 4.11509\n",
      "Epoch end time 02-06-2023 15:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [06:34<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 19, discriminator loss: 0.00000\n",
      "Epoch 1 of 19, generator loss: 3.10050\n",
      "Epoch end time 02-06-2023 15:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [07:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 19, discriminator loss: 0.00000\n",
      "Epoch 2 of 19, generator loss: 2.88922\n",
      "Epoch end time 02-06-2023 15:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [06:40<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 19, discriminator loss: 0.00000\n",
      "Epoch 3 of 19, generator loss: 2.78009\n",
      "Epoch end time 02-06-2023 16:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [06:20<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 of 19, discriminator loss: 0.00000\n",
      "Epoch 4 of 19, generator loss: 2.72695\n",
      "Epoch end time 02-06-2023 16:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [06:15<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 of 19, discriminator loss: 0.00000\n",
      "Epoch 5 of 19, generator loss: 2.65125\n",
      "Epoch end time 02-06-2023 16:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [05:54<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 of 19, discriminator loss: 0.00000\n",
      "Epoch 6 of 19, generator loss: 2.61035\n",
      "Epoch end time 02-06-2023 16:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [05:52<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 of 19, discriminator loss: 0.00000\n",
      "Epoch 7 of 19, generator loss: 2.53768\n",
      "Epoch end time 02-06-2023 16:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [05:23<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 of 19, discriminator loss: 0.00000\n",
      "Epoch 8 of 19, generator loss: 2.51223\n",
      "Epoch end time 02-06-2023 16:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [05:20<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 of 19, discriminator loss: 0.00000\n",
      "Epoch 9 of 19, generator loss: 2.49246\n",
      "Epoch end time 02-06-2023 16:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [05:22<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 19, discriminator loss: 0.00000\n",
      "Epoch 10 of 19, generator loss: 2.45236\n",
      "Epoch end time 02-06-2023 16:42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [05:27<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 of 19, discriminator loss: 0.00000\n",
      "Epoch 11 of 19, generator loss: 2.47527\n",
      "Epoch end time 02-06-2023 16:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [05:27<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 of 19, discriminator loss: 0.00000\n",
      "Epoch 12 of 19, generator loss: 2.43512\n",
      "Epoch end time 02-06-2023 16:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [05:28<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 of 19, discriminator loss: 0.00000\n",
      "Epoch 13 of 19, generator loss: 2.41783\n",
      "Epoch end time 02-06-2023 16:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 72/486 [00:55<04:39,  1.48it/s] "
     ]
    }
   ],
   "source": [
    "history = trainer.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    epoch_num=epoch_num\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T14:31:10.301259300Z",
     "start_time": "2023-06-02T12:35:30.500359400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "trainer.draw_history_plots()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "trainer.save_history_plots(save_directory)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "trainer.create_readme(save_directory)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "test_dataset = EncoderDecoderDataset(\n",
    "    image_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoderNew\\val\",\n",
    "    transform_human=transform_input,\n",
    "    transform_clothes=transform_input,\n",
    "    transform_human_restored=transform_real\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "generator.to('cpu')\n",
    "discriminator.to('cpu')\n",
    "image, real_image = test_dataset[2]\n",
    "image = image.unsqueeze(0)\n",
    "#print(image)\n",
    "print(image.shape)\n",
    "image = generator(image)\n",
    "imaged = discriminator(image)\n",
    "image = transforms.ToPILImage()(image[0, :, :, :])\n",
    "image.show()\n",
    "print(imaged)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
