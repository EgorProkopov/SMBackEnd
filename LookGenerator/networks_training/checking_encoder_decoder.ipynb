{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL.Image as Image\n",
    "import torch.cuda\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import LookGenerator.datasets.transforms as custom_transforms\n",
    "from LookGenerator.datasets.utils import prepare_images_for_encoder, to_array_from_decoder, load_image, convert_channel, show_array_as_image, save_array_as_image\n",
    "from LookGenerator.networks.encoder_decoder import EncoderDecoder\n",
    "from LookGenerator.networks.utils import load_model\n",
    "import cv2\n",
    "from tqdm import tqdm\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T21:38:47.649172Z",
     "end_time": "2023-04-03T21:38:47.651679Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка изображений"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-03T22:07:54.399798Z",
     "end_time": "2023-04-03T22:07:54.414674Z"
    }
   },
   "outputs": [],
   "source": [
    "#root = r\"C:\\Users\\Даша\\кто\\мусор\\zalando-hd-resized\\val\"\n",
    "root = r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\val\"\n",
    "file_name = r\"01046_00\"\n",
    "\n",
    "human_image = load_image(root, r\"imageWithNoCloth\", file_name, \".png\")\n",
    "clothes = load_image(root, r\"cloth\", file_name, r\".jpg\")\n",
    "\n",
    "pose_points = []\n",
    "points_list = os.listdir(os.path.join(\n",
    "    root,\n",
    "    r\"posePoints\",\n",
    "    file_name\n",
    "))\n",
    "print(len(points_list))\n",
    "for pose_point in points_list:\n",
    "    pose_point_image = convert_channel(load_image(root, os.path.join(r\"posePoints\", file_name), pose_point, \"\"))\n",
    "    pose_points.append(pose_point_image)\n",
    "\n",
    "# if model dataset has pose_points=False param:\n",
    "pose_points = []"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Определение трансформаций"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "input_rgb_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.Normalize()\n",
    "])\n",
    "\n",
    "input_bin_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.Normalize()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T22:07:54.967499Z",
     "end_time": "2023-04-03T22:07:54.968793Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка весов модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "model_input = prepare_images_for_encoder(human_image, pose_points, clothes, input_rgb_transform, input_bin_transform).float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T22:07:55.791388Z",
     "end_time": "2023-04-03T22:07:55.804208Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "#weights_dir = r\"C:\\Users\\Даша\\PycharmProjects\\SMBackEnd\\LookGenerator\\weights\\epoch_19.pt\"\n",
    "weights_dir = r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\encoder\\weights\\session19_2\\epoch_01.pt\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T22:07:56.026309Z",
     "end_time": "2023-04-03T22:07:56.036844Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "model = EncoderDecoder(in_channels=6, out_channels=3)\n",
    "model = load_model(model, weights_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T22:07:56.431153Z",
     "end_time": "2023-04-03T22:07:56.496975Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "device = 'cpu' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)\n",
    "model_input = model_input.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T22:07:57.715210Z",
     "end_time": "2023-04-03T22:07:57.717889Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Прогон модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "save_path = fr\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\out\\{file_name}.png\"\n",
    "save_path_old = fr\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\out\\{file_name}_old.png\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T22:08:04.263363Z",
     "end_time": "2023-04-03T22:08:04.273898Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "model_output = model(model_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T22:08:06.787447Z",
     "end_time": "2023-04-03T22:08:06.939967Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(model_output, save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T22:08:08.323048Z",
     "end_time": "2023-04-03T22:08:08.338863Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Отображение результата"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "model_output = to_array_from_decoder(model_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T21:38:27.467146Z",
     "end_time": "2023-04-03T21:38:27.486930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "to_plt = np.array(model_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T21:38:27.662538Z",
     "end_time": "2023-04-03T21:38:27.672573Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "c = np.array(to_plt[:,:,0])\n",
    "to_plt[:,:,0] = to_plt[:,:,2]\n",
    "to_plt[:,:,2] = c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T21:38:27.879312Z",
     "end_time": "2023-04-03T21:38:27.887840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_array_as_image(np.invert(np.uint8(255*to_plt)))\n",
    "#save_array_as_image(np.uint8(255*model_output), save_path=save_path_old)\n",
    "# cv2.imwrite(fr\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\out\\{file_name}.png\", cv2.cvtColor(np.uint8(255*model_output), cv2.COLOR_RGB2BGR) )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:06.025677Z",
     "end_time": "2023-04-02T23:52:06.106783Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "dir_ = r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\val\\imageWithNoCloth\"\n",
    "list_files = os.listdir(dir_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T21:49:40.683852Z",
     "end_time": "2023-04-03T21:49:40.708617Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "input_rgb_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.Normalize()\n",
    "])\n",
    "\n",
    "input_bin_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.Normalize()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T21:49:41.465580Z",
     "end_time": "2023-04-03T21:49:41.491111Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "weights_dir = r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\encoder\\weights\\session19_2\\epoch_01.pt\"\n",
    "model = EncoderDecoder(in_channels=6, out_channels=3)\n",
    "model = load_model(model, weights_dir)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T21:49:42.961137Z",
     "end_time": "2023-04-03T21:49:43.118150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for file_name_ in tqdm(list_files[:150]):\n",
    "    root = r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\val\"\n",
    "    file_name = file_name_[:-4]\n",
    "\n",
    "    human_image = load_image(root, r\"imageWithNoCloth\", file_name, \".png\")\n",
    "    clothes = load_image(root, r\"cloth\", file_name, r\".jpg\")\n",
    "\n",
    "    pose_points = []\n",
    "    points_list = os.listdir(os.path.join(\n",
    "        root,\n",
    "        r\"posePoints\",\n",
    "        file_name\n",
    "    ))\n",
    "    for pose_point in points_list:\n",
    "        pose_point_image = convert_channel(load_image(root, os.path.join(r\"posePoints\", file_name), pose_point, \"\"))\n",
    "        pose_points.append(pose_point_image)\n",
    "\n",
    "    # if model dataset has pose_points=False param:\n",
    "    pose_points = []\n",
    "    model_input = prepare_images_for_encoder(human_image, pose_points, clothes, input_rgb_transform, input_bin_transform).float()\n",
    "    model_input = model_input.to(device)\n",
    "\n",
    "    save_path = fr\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\out\\{file_name}.png\"\n",
    "    model_output = model(model_input)\n",
    "    torchvision.utils.save_image(model_output.to('cpu'), save_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T21:49:47.689895Z",
     "end_time": "2023-04-03T21:50:00.288271Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
