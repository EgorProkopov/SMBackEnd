{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL.Image as Image\n",
    "import torch.cuda\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import LookGenerator.datasets.transforms as custom_transforms\n",
    "from LookGenerator.datasets.utils import prepare_images_for_encoder, to_array_from_decoder, load_image, convert_channel, show_array_as_image, save_array_as_image\n",
    "from LookGenerator.networks.encoder_decoder import EncoderDecoder\n",
    "from LookGenerator.networks.utils import load_model\n",
    "import cv2\n",
    "from tqdm import tqdm\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T00:02:11.247941Z",
     "end_time": "2023-04-03T00:02:12.584964Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка изображений"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:02.335051Z",
     "end_time": "2023-04-02T23:52:02.346644Z"
    }
   },
   "outputs": [],
   "source": [
    "#root = r\"C:\\Users\\Даша\\кто\\мусор\\zalando-hd-resized\\val\"\n",
    "root = r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\val\"\n",
    "file_name = r\"00013_00\"\n",
    "\n",
    "human_image = load_image(root, r\"imageWithNoCloth\", file_name, \".png\")\n",
    "clothes = load_image(root, r\"cloth\", file_name, r\".jpg\")\n",
    "\n",
    "pose_points = []\n",
    "points_list = os.listdir(os.path.join(\n",
    "    root,\n",
    "    r\"posePoints\",\n",
    "    file_name\n",
    "))\n",
    "print(len(points_list))\n",
    "for pose_point in points_list:\n",
    "    pose_point_image = convert_channel(load_image(root, os.path.join(r\"posePoints\", file_name), pose_point, \"\"))\n",
    "    pose_points.append(pose_point_image)\n",
    "\n",
    "# if model dataset has pose_points=False param:\n",
    "pose_points = []"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Определение трансформаций"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "input_rgb_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.Normalize()\n",
    "])\n",
    "\n",
    "input_bin_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.Normalize()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:02.697420Z",
     "end_time": "2023-04-02T23:52:02.698923Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка весов модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "model_input = prepare_images_for_encoder(human_image, pose_points, clothes, input_rgb_transform, input_bin_transform).float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:03.041481Z",
     "end_time": "2023-04-02T23:52:03.051516Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "#weights_dir = r\"C:\\Users\\Даша\\PycharmProjects\\SMBackEnd\\LookGenerator\\weights\\epoch_19.pt\"\n",
    "weights_dir = r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\encoder\\weights\\session18\\epoch_09.pt\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:03.233285Z",
     "end_time": "2023-04-02T23:52:03.253782Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "model = EncoderDecoder(in_channels=6, out_channels=3)\n",
    "model = load_model(model, weights_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:03.433526Z",
     "end_time": "2023-04-02T23:52:03.492940Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "device = 'cpu' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)\n",
    "model_input = model_input.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:03.627682Z",
     "end_time": "2023-04-02T23:52:03.644768Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Прогон модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "save_path = fr\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\out\\{file_name}.png\"\n",
    "save_path_old = fr\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\out\\{file_name}_old.png\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:04.032956Z",
     "end_time": "2023-04-02T23:52:04.038247Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "model_output = model(model_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:04.242003Z",
     "end_time": "2023-04-02T23:52:04.367231Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(model_output, save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:04.465221Z",
     "end_time": "2023-04-02T23:52:04.484791Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Отображение результата"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "model_output = to_array_from_decoder(model_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:05.009104Z",
     "end_time": "2023-04-02T23:52:05.023403Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "to_plt = np.array(model_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:05.280441Z",
     "end_time": "2023-04-02T23:52:05.286566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "c = np.array(to_plt[:,:,0])\n",
    "to_plt[:,:,0] = to_plt[:,:,2]\n",
    "to_plt[:,:,2] = c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:05.714512Z",
     "end_time": "2023-04-02T23:52:05.720127Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_array_as_image(np.invert(np.uint8(255*to_plt)))\n",
    "#save_array_as_image(np.uint8(255*model_output), save_path=save_path_old)\n",
    "# cv2.imwrite(fr\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\out\\{file_name}.png\", cv2.cvtColor(np.uint8(255*model_output), cv2.COLOR_RGB2BGR) )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T23:52:06.025677Z",
     "end_time": "2023-04-02T23:52:06.106783Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dir_ = r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\val\\imageWithNoCloth\"\n",
    "list_files = os.listdir(dir_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T00:02:12.892922Z",
     "end_time": "2023-04-03T00:02:12.903653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "input_rgb_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.Normalize()\n",
    "])\n",
    "\n",
    "input_bin_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.Normalize()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T00:02:13.599361Z",
     "end_time": "2023-04-03T00:02:13.613912Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "weights_dir = r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\encoder\\weights\\session18\\epoch_09.pt\"\n",
    "model = EncoderDecoder(in_channels=6, out_channels=3)\n",
    "model = load_model(model, weights_dir)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T00:02:14.781679Z",
     "end_time": "2023-04-03T00:02:14.956356Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for file_name_ in tqdm(list_files[:150]):\n",
    "    root = r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\val\"\n",
    "    file_name = file_name_[:-4]\n",
    "\n",
    "    human_image = load_image(root, r\"imageWithNoCloth\", file_name, \".png\")\n",
    "    clothes = load_image(root, r\"cloth\", file_name, r\".jpg\")\n",
    "\n",
    "    pose_points = []\n",
    "    points_list = os.listdir(os.path.join(\n",
    "        root,\n",
    "        r\"posePoints\",\n",
    "        file_name\n",
    "    ))\n",
    "    for pose_point in points_list:\n",
    "        pose_point_image = convert_channel(load_image(root, os.path.join(r\"posePoints\", file_name), pose_point, \"\"))\n",
    "        pose_points.append(pose_point_image)\n",
    "\n",
    "    # if model dataset has pose_points=False param:\n",
    "    pose_points = []\n",
    "    model_input = prepare_images_for_encoder(human_image, pose_points, clothes, input_rgb_transform, input_bin_transform).float()\n",
    "    model_input = model_input.to(device)\n",
    "\n",
    "    save_path = fr\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoder\\out\\{file_name}.png\"\n",
    "    model_output = model(model_input)\n",
    "    torchvision.utils.save_image(model_output.to('cpu'), save_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T00:02:20.140029Z",
     "end_time": "2023-04-03T00:02:31.187604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
