{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.cuda\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from LookGenerator.networks.clothes_feature_extractor import ClothingAutoEncoder\n",
    "from LookGenerator.datasets.basic_dataset import BasicDataset\n",
    "from LookGenerator.networks.losses import VAELoss\n",
    "from LookGenerator.networks.utils import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform_input = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size_train = 32\n",
    "batch_size_val = 16\n",
    "pin_memory = True\n",
    "num_workers = 8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = BasicDataset(\n",
    "    root_dir=\"\",\n",
    "    dir_name=\"\",\n",
    "    transform_input=transform_input\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size_train, shuffle=True, pin_memory=pin_memory,\n",
    "    num_workers=num_workers\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_dataset = BasicDataset(\n",
    "    root_dir=\"\",\n",
    "    dir_name=\"\",\n",
    "    transform_input=transform_input\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size_train, shuffle=True, pin_memory=pin_memory,\n",
    "    num_workers=num_workers\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fit(model, criterion, optimizer, device, train_loader, val_loader, epochs):\n",
    "\n",
    "    train_loss=[]\n",
    "    val_loss=[]\n",
    "\n",
    "    criterion = criterion.to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "\n",
    "        train_epoch_loss = []\n",
    "        for X_batch, _ in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X_batch)\n",
    "            reconstructed, mu, log_var = pred\n",
    "            loss = criterion(X_batch, mu, log_var, reconstructed)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch_loss.append(loss.item())\n",
    "\n",
    "        train_loss.append(np.mean(train_epoch_loss))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss_epoch = []\n",
    "        with torch.no_grad():\n",
    "          for X_val, _ in val_loader:\n",
    "              X_val = X_val.to(device)\n",
    "              pred = model(X_val)\n",
    "              reconstructed, mu, log_var  = pred\n",
    "              loss, _, _ = criterion(X_val, mu, log_var, reconstructed)\n",
    "              val_loss_epoch.append(loss.item())\n",
    "        val_loss.append(np.mean(val_loss_epoch))\n",
    "\n",
    "        print(\"Epoch [{}/{}], train_loss: {:.3f}, val_loss: {:.3f}\".format(\n",
    "            epoch+1, epochs,\n",
    "            train_loss[-1], val_loss[-1])\n",
    "        )\n",
    "\n",
    "    return train_loss, val_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = VAELoss()\n",
    "model = ClothingAutoEncoder()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 10e-3)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loss, val_loss = fit(model=model,\n",
    "                           criterion=criterion,\n",
    "                           optimizer=optimizer,\n",
    "                           train_loader=train_dataloader,\n",
    "                           val_loader=val_dataloader,\n",
    "                           epochs=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(val_loss, label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for X_val, _ in val_dataloader:\n",
    "  reconstructed, mu, log_var = model(X_val.to(device))\n",
    "  img = transforms.ToPILImage()(reconstructed[0]/2+0.5)\n",
    "  cl = transforms.ToPILImage()(X_val[0])\n",
    "  cl.show()\n",
    "  img.show()\n",
    "  break"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
