{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:17:06.313063200Z",
     "start_time": "2023-06-01T12:17:05.087173700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from LookGenerator.datasets.tps_dataset import ShirtsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from LookGenerator.networks.bpgm.model.models import BPGM\n",
    "from LookGenerator.networks.bpgm.train_bpgm import train_bpgm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "from LookGenerator.networks_training.utils import check_path_and_creat\n",
    "from LookGenerator.networks.utils import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,192)),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((256,192)),\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:17:06.316033900Z",
     "start_time": "2023-06-01T12:17:06.313063200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 0\n",
    "pin_memory = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:17:06.323884800Z",
     "start_time": "2023-06-01T12:17:06.316033900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = ShirtsDataset(\n",
    "    root=r\"C:\\Users\\DenisovDmitrii\\Desktop\\zalando-hd-resize\\train\",\n",
    "    transform=transform,\n",
    "    transform_mask=mask_transform\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=num_workers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:17:06.333370300Z",
     "start_time": "2023-06-01T12:17:06.324888800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory = r'C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\tps\\weights\\test'\n",
    "check_path_and_creat(save_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:17:06.342000400Z",
     "start_time": "2023-06-01T12:17:06.333370300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DenisovDmitrii\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:17:11.713478500Z",
     "start_time": "2023-06-01T12:17:06.336982600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:17:11.718496200Z",
     "start_time": "2023-06-01T12:17:11.713478500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization method [normal]\n",
      "initialization method [normal]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BPGM(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:17:11.858848Z",
     "start_time": "2023-06-01T12:17:11.717492900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DenisovDmitrii\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DenisovDmitrii\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 182/182 [15:58<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss = train_bpgm(dataloader=dataloader,\n",
    "                  model=model, device=device, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:33:10.833093900Z",
     "start_time": "2023-06-01T12:17:11.857844800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "save_model(model.to('cpu'), path=f\"{save_directory}\\\\epoch_02.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:33:10.897222300Z",
     "start_time": "2023-06-01T12:33:10.834097600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# тест"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "test_dataset = ShirtsDataset(\n",
    "    root=r\"C:\\Users\\DenisovDmitrii\\Desktop\\zalando-hd-resize\\test\",\n",
    "    transform=transform,\n",
    "    transform_mask=mask_transform\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T19:10:15.686014600Z",
     "start_time": "2023-05-31T19:10:15.670314500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "topil = transforms.ToPILImage()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:33:10.899626500Z",
     "start_time": "2023-06-01T12:33:10.897222300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "testdataloader = DataLoader(test_dataset, batch_size=1, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T19:10:18.664984300Z",
     "start_time": "2023-05-31T19:10:18.635883100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "weights_dir = r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\tps\\weights\\test\\epoch_00.pt\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T10:33:06.662842800Z",
     "start_time": "2023-06-01T10:33:06.660835700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = load_model(model, weights_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T10:33:07.259770400Z",
     "start_time": "2023-06-01T10:33:07.211677800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in testdataloader:\n",
    "    mask = data['segmentation'].to(device)\n",
    "    shirt = data['shirt'].to(device)\n",
    "    shirt_mask = data['shirt_mask'].to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    theta = model(mask, shirt)\n",
    "\n",
    "    warped = F.grid_sample(shirt, theta, padding_mode='border', align_corners=True).to('cpu')\n",
    "\n",
    "    warped_mask = F.grid_sample(shirt_mask, theta, padding_mode='border', align_corners=True).to('cpu')\n",
    "    warped_mask = topil(warped_mask[0])\n",
    "    warped_mask.show()\n",
    "    warped = topil(warped[0]/2+0.5)\n",
    "    warped.show()\n",
    "    count += 1\n",
    "    if count == 4:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T19:20:02.683557500Z",
     "start_time": "2023-05-31T19:19:37.118697300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "подготовка"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "path_people = r'C:\\Users\\DenisovDmitrii\\Desktop\\forEncoderNew\\train\\imageWithNoCloth'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:33:10.906372700Z",
     "start_time": "2023-06-01T12:33:10.899626500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cloud_people = os.listdir(path_people)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:33:10.921412900Z",
     "start_time": "2023-06-01T12:33:10.906372700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "11647"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cloud_people)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:33:10.923714600Z",
     "start_time": "2023-06-01T12:33:10.921412900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 192, 3) (256, 192, 3)\n",
      "(256, 192, 3) (256, 192, 3)\n",
      "(256, 192, 3) (256, 192, 3)\n",
      "(256, 192, 3) (256, 192, 3)\n"
     ]
    }
   ],
   "source": [
    "# ИСПОЛЬЗОВАТЬ batch_size=1\n",
    "count = 0\n",
    "for index, data in enumerate(dataloader):\n",
    "\n",
    "    cloud_person = Image.open(path_people + \"\\\\\" + cloud_people[index])\n",
    "    cloud_person = np.array(cloud_person)\n",
    "\n",
    "    mask = data['segmentation'].to(device)\n",
    "    shirt = data['shirt'].to(device)\n",
    "    shirt_mask = data['shirt_mask'].to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    theta = model(mask, shirt)\n",
    "\n",
    "    warped = F.grid_sample(shirt, theta, padding_mode='border', align_corners=True).to('cpu')\n",
    "\n",
    "    warped_mask = F.grid_sample(shirt_mask, theta, padding_mode='border', align_corners=True).to('cpu')\n",
    "    warped = warped / 2 + 0.5\n",
    "    wc = warped * warped_mask\n",
    "    # wc = transforms.Resize((256 + 256 // 2, 192 + 192 // 2))(wc)\n",
    "    # wc = transforms.CenterCrop((256, 192))(wc)\n",
    "    warped_mask = np.array(topil(warped_mask[0]))\n",
    "    # warped = np.array(topil(warped[0]))\n",
    "    wc = np.array(topil(wc[0]))\n",
    "    # wc = np.concatenate((warped[:,:,0] * warped_mask, warped[:,:,1] * warped_mask, warped[:,:,2] * warped_mask), axis=2)\n",
    "    # wc = warped * warped_mask\n",
    "    # wc += warped[:,:,1] * warped_mask\n",
    "    # wc += warped[:,:,2] * warped_mask\n",
    "    print(wc.shape, cloud_person.shape)\n",
    "    person = cloud_person + wc\n",
    "\n",
    "    Image.fromarray(person, 'RGB').save(path_people + \"2\\\\\" + cloud_people[index])\n",
    "    count += 1\n",
    "    if count == 4:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T12:33:29.288322100Z",
     "start_time": "2023-06-01T12:33:10.924711Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
