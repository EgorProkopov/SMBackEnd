{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations\n",
    "from LookGenerator.networks.losses import PerceptualLoss, PerPixelLoss\n",
    "from LookGenerator.datasets.encoder_decoder_datasets import GenerativeDatasetWithMask\n",
    "from LookGenerator.networks.trainer import Trainer\n",
    "from LookGenerator.networks.clothes_feature_extractor import ClothAutoencoder\n",
    "from LookGenerator.networks.encoder_decoder import EncoderDecoder\n",
    "from LookGenerator.networks_training.utils import check_path_and_creat\n",
    "import LookGenerator.datasets.transforms as custom_transforms\n",
    "from LookGenerator.networks.utils import load_model\n",
    "from LookGenerator.networks.utils import get_num_digits, save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform_human = transforms.Compose([\n",
    "    transforms.Resize((256, 192)) #,\n",
    "    # transforms.RandomAffine(scale=(0.8, 1), degrees=(-90,90), fill = 0.9),\n",
    "    # transforms.ColorJitter(brightness=(0.5, 1), contrast=(0.4,1),  hue=(0, 0.3)),\n",
    "    # transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "    #                      std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_clothes = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    # transforms.ColorJitter(brightness=(0.5, 1), contrast=(0.4,1),  hue=(0, 0.3)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.ThresholdTransform()\n",
    "])\n",
    "\n",
    "transform_human_restored = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    # transforms.RandomAffine(scale=(0.8, 1), degrees=(-90,90), fill = 0.9),\n",
    "    # transforms.ColorJitter(brightness=(0.5, 1), contrast=(0.4,1),  hue=(0, 0.3)),\n",
    "    custom_transforms.MinMaxScale()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size_train = 32\n",
    "batch_size_val = 16\n",
    "pin_memory = True\n",
    "num_workers = 12"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = GenerativeDatasetWithMask(\n",
    "    human_dir=\"\",\n",
    "    clothes_dir=\"\",\n",
    "    segmentation_mask_dir=\"\",\n",
    "    human_restored_dir=\"\",\n",
    "    transform_human=transform_human,\n",
    "    transform_clothes=transform_clothes,\n",
    "    transform_mask=transform_mask,\n",
    "    transform_human_restored=transform_human_restored\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size_train, shuffle=True, pin_memory=pin_memory, num_workers=num_workers\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_dataset = GenerativeDatasetWithMask(\n",
    "    human_dir=\"\",\n",
    "    clothes_dir=\"\",\n",
    "    segmentation_mask_dir=\"\",\n",
    "    human_restored_dir=\"\",\n",
    "    transform_human=transform_human,\n",
    "    transform_clothes=transform_clothes,\n",
    "    transform_mask=transform_mask,\n",
    "    transform_human_restored=transform_human_restored\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size_val, shuffle=False, pin_memory=pin_memory, num_workers=num_workers\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Лосс"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EncoderDecoderWithMaskLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder-decoder custom loss\n",
    "    \"\"\"\n",
    "    def __init__(self, device='cpu', weights=[1.0, 1.0, 1.0]):\n",
    "        super(EncoderDecoderWithMaskLoss, self).__init__()\n",
    "        self.perceptual_loss = PerceptualLoss(device, weights_perceptual=[1.0, 1.0, 1.0, 1.0])\n",
    "        self.per_pixel_loss = PerPixelLoss().to(device)\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, outputs, mask, targets):\n",
    "        perceptual = self.perceptual_loss(outputs, targets)\n",
    "        per_pixel = self.per_pixel_loss(outputs, targets)\n",
    "        outputs_masked = outputs*mask\n",
    "        targets_masked = targets*mask\n",
    "        per_pixel_masked = self.per_pixel_loss(outputs_masked, targets_masked)\n",
    "\n",
    "        loss = (self.weights[0] * perceptual + self.weights[1] * per_pixel + self.weights * per_pixel_masked) / sum(self.weights)\n",
    "\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clothes_feature_extractor = ClothAutoencoder(\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    features=(8, 16, 32, 64),\n",
    "    latent_dim_size=128,\n",
    "    encoder_activation_func=nn.LeakyReLU(),\n",
    "    decoder_activation_func=nn.ReLU()\n",
    ")\n",
    "clothes_feature_extractor = load_model(clothes_feature_extractor, r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\autoDegradation\\weights\\testClothes_L1Loss_4features\\epoch_39.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = EncoderDecoder(clothes_feature_extractor, in_channels=6, out_channels=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "criterion = EncoderDecoderWithMaskLoss(device=device, weights=[1.0, 1.0, 1.0])\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_directory=r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\newEncoder\\weights\\testBaseParams\"\n",
    "check_path_and_creat(save_directory)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TrainerWithMask:\n",
    "    \"\"\"\n",
    "    Class for model training\n",
    "    \"\"\"\n",
    "    def __init__(self, model_, optimizer, criterion, device='cpu', save_directory=r\"\", save_step=1, verbose=True):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            model_: model to train\n",
    "            optimizer: model optimizer\n",
    "            criterion: loss function for this model\n",
    "            device: training device. Default: cpu\n",
    "            save_directory: Path for this training session directory. Default: \"\"\n",
    "            save_step: Step between epoch saves. Default: 1\n",
    "            verbose: If 'True', will print verbose output of the model\n",
    "        \"\"\"\n",
    "        self.model = model_\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        device = torch.device(device)\n",
    "        self.device = device\n",
    "        self.criterion.to(self.device)\n",
    "\n",
    "        self.train_history_epochs = []\n",
    "        self.val_history_epochs = []\n",
    "\n",
    "        self.train_history_batches = []\n",
    "        self.val_history_batches = []\n",
    "\n",
    "        self.save_directory = save_directory\n",
    "        self.save_step = save_step\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader, epoch_num=5):\n",
    "        \"\"\"\n",
    "        Train function\n",
    "        Args:\n",
    "            train_dataloader: dataloader for training\n",
    "            val_dataloader: dataloader for validation\n",
    "            epoch_num: number of epoch for training and validation\n",
    "        \"\"\"\n",
    "        start = datetime.datetime.now()\n",
    "        print(\"start time\", start.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "\n",
    "        for epoch in range(epoch_num):\n",
    "            # Train\n",
    "            train_loss = self._train_epoch(train_dataloader)\n",
    "            self.train_history_epochs.append(train_loss)\n",
    "            if self.verbose:\n",
    "                print(f'Epoch {epoch} of {epoch_num - 1}, train loss: {train_loss:.5f}')\n",
    "                now = datetime.datetime.now()\n",
    "                print(\"Epoch end time\", now.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Validation\n",
    "            val_loss = self._val_epoch(val_dataloader)\n",
    "            self.val_history_epochs.append(val_loss)\n",
    "            if self.verbose:\n",
    "                print(f'Epoch {epoch} of {epoch_num - 1}, val loss: {val_loss:.5f}')\n",
    "                now = datetime.datetime.now()\n",
    "                print(\"Epoch end time\", now.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Save\n",
    "            if self.save_step == 0 or self.save_directory == \"\":\n",
    "                continue\n",
    "            if (epoch + 1) % self.save_step == 0:\n",
    "                save_model(self.model.to('cpu'), path=f\"{self.save_directory}\\\\epoch_{self._epoch_string(epoch, epoch_num)}.pt\")\n",
    "\n",
    "        now = datetime.datetime.now()\n",
    "        print(\"end time\", now.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "        print(\"delta\", now - start)\n",
    "\n",
    "    def _train_epoch(self, train_dataloader):\n",
    "        \"\"\"\n",
    "        Method for epoch training\n",
    "        Args:\n",
    "            train_dataloader:  train dataloader\n",
    "\n",
    "        Returns: train loss\n",
    "\n",
    "        \"\"\"\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        train_running_loss = 0.0\n",
    "        self.model.train()\n",
    "        for data, mask, targets in tqdm(train_dataloader):\n",
    "            data = data.to(self.device)\n",
    "            mask = mask.to(self.device)\n",
    "            targets = targets.to(self.device)\n",
    "            outputs = self.model(data)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.criterion(outputs, mask, targets)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            loss_number = loss.item()\n",
    "            train_running_loss += loss_number\n",
    "            self.train_history_batches.append(loss_number)\n",
    "\n",
    "        train_loss = train_running_loss / len(train_dataloader)\n",
    "        return train_loss\n",
    "\n",
    "    def _val_epoch(self, val_dataloader):\n",
    "        \"\"\"\n",
    "        Method for epoch validation\n",
    "        Args:\n",
    "            val_dataloader:\n",
    "\n",
    "        Returns: validation loss\n",
    "\n",
    "        \"\"\"\n",
    "        val_running_loss = 0.0\n",
    "        self.model.eval()\n",
    "        for data, mask, targets in tqdm(val_dataloader):\n",
    "            data = data.to(self.device)\n",
    "            mask = mask.to(self.device)\n",
    "            targets = targets.to(self.device)\n",
    "            outputs = self.model(data)\n",
    "\n",
    "            loss = self.criterion(outputs, mask, targets)\n",
    "            loss_number = loss.item()\n",
    "            val_running_loss += loss_number\n",
    "            self.val_history_batches.append(loss_number)\n",
    "\n",
    "        val_loss = val_running_loss / len(val_dataloader)\n",
    "        return val_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def _epoch_string(epoch, epoch_num):\n",
    "        \"\"\"\n",
    "        Method to create a string form of current epoch number, using the same number\n",
    "        of digits for every training session\n",
    "\n",
    "        Args:\n",
    "            epoch: number of current epoch\n",
    "            epoch_num: number of epochs for this training session\n",
    "\n",
    "        Returns: converted to string epoch number\n",
    "\n",
    "        \"\"\"\n",
    "        num_digits_epoch_num = get_num_digits(epoch_num)\n",
    "        num_digits_epoch = get_num_digits(epoch)\n",
    "\n",
    "        epoch_string = \"0\"*(num_digits_epoch_num - num_digits_epoch) + str(epoch)\n",
    "        return epoch_string\n",
    "\n",
    "    def draw_history_plots(self, epochs=True):\n",
    "        \"\"\"\n",
    "        Draws plots of train and validation\n",
    "\n",
    "        Args:\n",
    "            epochs: TODO: if 'True', draws history plots by epochs, else by batches\n",
    "        \"\"\"\n",
    "        if epochs:\n",
    "            plt.plot(self.train_history_epochs, label=\"train\")\n",
    "            plt.plot(self.val_history_epochs, label=\"val\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.plot(self.train_history_batches, label=\"train\")\n",
    "            plt.plot(self.val_history_batches, label=\"val\")\n",
    "            plt.show()\n",
    "\n",
    "    def __str__(self):\n",
    "        description = f\"Model:\\n\\t{str(self.model)}\\n\" \\\n",
    "                      f\"Criterion: \\n\\t{str(type(self.criterion))}\\n\" \\\n",
    "                      f\"Optimizer: \\n\\t{str(type(self.optimizer))}\"\n",
    "        return description"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model_=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    save_directory=save_directory,\n",
    "    save_step=1,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train(train_dataloader, val_dataloader, epoch_num=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.draw_history_plots()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(str(trainer))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file = open(os.path.join(save_directory, \"readme.txt\"), 'w')\n",
    "file.write(str(trainer))\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
