{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:23:29.383489800Z",
     "start_time": "2023-05-31T15:23:27.679541400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations\n",
    "from LookGenerator.networks.losses import PerceptualLoss, PerPixelLoss\n",
    "from LookGenerator.datasets.encoder_decoder_datasets import GenerativeDatasetWithMask\n",
    "from LookGenerator.networks.trainer import Trainer, TrainerWithMask\n",
    "from LookGenerator.networks.clothes_feature_extractor import ClothAutoencoder\n",
    "from LookGenerator.networks.encoder_decoder import EncoderDecoder\n",
    "from LookGenerator.networks_training.utils import check_path_and_creat\n",
    "import LookGenerator.datasets.transforms as custom_transforms\n",
    "from LookGenerator.networks.utils import load_model\n",
    "from LookGenerator.networks.utils import get_num_digits, save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "transform_human = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.RandomAffine(scale=(0.8, 1), degrees=(-90,90), fill = 0.9),\n",
    "    #transforms.ColorJitter(brightness=(0.5, 1), contrast=(0.4,1),  hue=(0, 0.3)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_clothes = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    # transforms.ColorJitter(brightness=(0.5, 1), contrast=(0.4,1),  hue=(0, 0.3)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    custom_transforms.ThresholdTransform()\n",
    "])\n",
    "\n",
    "transform_human_restored = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.RandomAffine(scale=(0.8, 1), degrees=(-90,90), fill = 0.9),\n",
    "    # transforms.ColorJitter(brightness=(0.5, 1), contrast=(0.4,1),  hue=(0, 0.3)),\n",
    "    custom_transforms.MinMaxScale()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:23:29.392073500Z",
     "start_time": "2023-05-31T15:23:29.383489800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "batch_size_train = 32\n",
    "batch_size_val = 16\n",
    "pin_memory = True\n",
    "num_workers = 8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:23:29.586941800Z",
     "start_time": "2023-05-31T15:23:29.580420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_dataset = GenerativeDatasetWithMask(\n",
    "    human_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoderNew\\train\\imageWithNoCloth\",\n",
    "    clothes_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoderNew\\train\\cloth\",\n",
    "    segmentation_mask_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\zalando-hd-resize\\train\\agnostic-v3.3\",\n",
    "    human_restored_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoderNew\\train\\image\",\n",
    "    transform_human=transform_human,\n",
    "    transform_clothes=transform_clothes,\n",
    "    transform_mask=transform_mask,\n",
    "    transform_human_restored=transform_human_restored\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size_train, shuffle=True, pin_memory=pin_memory, num_workers=num_workers\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:23:32.663593800Z",
     "start_time": "2023-05-31T15:23:32.645141200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "val_dataset = GenerativeDatasetWithMask(\n",
    "    human_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoderNew\\val\\imageWithNoCloth\",\n",
    "    clothes_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoderNew\\val\\cloth\",\n",
    "    segmentation_mask_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\zalando-hd-resize\\test\\agnostic-v3.3\",\n",
    "    human_restored_dir=r\"C:\\Users\\DenisovDmitrii\\Desktop\\forEncoderNew\\val\\image\",\n",
    "    transform_human=transform_human,\n",
    "    transform_clothes=transform_clothes,\n",
    "    transform_mask=transform_mask,\n",
    "    transform_human_restored=transform_human_restored\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size_val, shuffle=False, pin_memory=pin_memory, num_workers=num_workers\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:23:34.058584Z",
     "start_time": "2023-05-31T15:23:34.051165300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6, 256, 192])\n",
      "torch.Size([32, 1, 256, 192])\n",
      "torch.Size([32, 3, 256, 192])\n"
     ]
    }
   ],
   "source": [
    "for X, mask, y in train_dataloader:\n",
    "    print(X.shape)\n",
    "    print(mask.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:23:48.849213400Z",
     "start_time": "2023-05-31T15:23:34.682925100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Лосс"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class EncoderDecoderWithMaskLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder-decoder custom loss for in-painting task\n",
    "    \"\"\"\n",
    "    def __init__(self, device='cpu', weights=[1.0, 1.0, 1.0, 1.0]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            device: device for loss computation\n",
    "            weights: weights of loss part:\n",
    "                - 1st weight: weight of base perceptual loss\n",
    "                - 2nd weight: weight of masked perceptual loss\n",
    "                - 3rd weight: weight of base per pixel loss\n",
    "                - 4th weight: weight of masked per pixel loss\n",
    "        \"\"\"\n",
    "        super(EncoderDecoderWithMaskLoss, self).__init__()\n",
    "        self.perceptual_loss = PerceptualLoss(device, weights_perceptual=[1.0, 1.0, 1.0, 1.0])\n",
    "        self.per_pixel_loss = PerPixelLoss().to(device)\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, outputs, mask, targets):\n",
    "        perceptual = self.perceptual_loss(outputs, targets)\n",
    "        per_pixel = self.per_pixel_loss(outputs, targets)\n",
    "        outputs_masked = outputs*mask\n",
    "        targets_masked = targets*mask\n",
    "        perceptual_masked = self.perceptual_loss(outputs_masked, targets_masked)\n",
    "        per_pixel_masked = self.per_pixel_loss(outputs_masked, targets_masked)\n",
    "\n",
    "        loss = (self.weights[0] * perceptual + self.weights[1] * perceptual_masked +  self.weights[2] * per_pixel + self.weights[3] * per_pixel_masked) / sum(self.weights)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def __repr__(self):\n",
    "        description = f\"Encoder-decoder custom loss for in-painting task\\n:\" \\\n",
    "                      f\"\\t Perceptual loss: {repr(self.perceptual_loss)}\\n\" \\\n",
    "                      f\"\\t per_pixel_loss: {repr(self.per_pixel_loss)}\\n\" \\\n",
    "                      f\"\\t weights: {str(self.weights)}\"\n",
    "        return description"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:23:54.472542700Z",
     "start_time": "2023-05-31T15:23:54.469032500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "clothes_feature_extractor = ClothAutoencoder(\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    features=(8, 16, 32, 64),\n",
    "    latent_dim_size=128,\n",
    "    encoder_activation_func=nn.LeakyReLU(),\n",
    "    decoder_activation_func=nn.ReLU()\n",
    ")\n",
    "clothes_feature_extractor = load_model(clothes_feature_extractor, r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\autoDegradation\\weights\\testClothes_L1Loss_4features\\epoch_39.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:23:56.949897400Z",
     "start_time": "2023-05-31T15:23:56.942969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DenisovDmitrii\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DenisovDmitrii\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model = EncoderDecoder(clothes_feature_extractor, in_channels=6, out_channels=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "criterion = EncoderDecoderWithMaskLoss(device=device, weights=[1.0, 1.0, 0.0, 2.0])\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:23:58.028643400Z",
     "start_time": "2023-05-31T15:23:57.349490300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory=r\"C:\\Users\\DenisovDmitrii\\OneDrive - ITMO UNIVERSITY\\peopleDetector\\newEncoder\\weights\\testWithMask_weights102_augment\"\n",
    "check_path_and_creat(save_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:23:59.623955500Z",
     "start_time": "2023-05-31T15:23:59.611136100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:24:02.786110500Z",
     "start_time": "2023-05-31T15:24:02.780592500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# class TrainerWithMask:\n",
    "#     \"\"\"\n",
    "#     Class for model training\n",
    "#     \"\"\"\n",
    "#     def __init__(self, model_, optimizer, criterion, device='cpu', save_directory=r\"\", save_step=1, verbose=True):\n",
    "#         \"\"\"\n",
    "#\n",
    "#         Args:\n",
    "#             model_: model to train\n",
    "#             optimizer: model optimizer\n",
    "#             criterion: loss function for this model\n",
    "#             device: training device. Default: cpu\n",
    "#             save_directory: Path for this training session directory. Default: \"\"\n",
    "#             save_step: Step between epoch saves. Default: 1\n",
    "#             verbose: If 'True', will print verbose output of the model\n",
    "#         \"\"\"\n",
    "#         self.model = model_\n",
    "#         self.optimizer = optimizer\n",
    "#         self.criterion = criterion\n",
    "#         device = torch.device(device)\n",
    "#         self.device = device\n",
    "#         self.criterion.to(self.device)\n",
    "#\n",
    "#         self.train_history_epochs = []\n",
    "#         self.val_history_epochs = []\n",
    "#\n",
    "#         self.train_history_batches = []\n",
    "#         self.val_history_batches = []\n",
    "#\n",
    "#         self.save_directory = save_directory\n",
    "#         self.save_step = save_step\n",
    "#         self.verbose = verbose\n",
    "#\n",
    "#     def train(self, train_dataloader, val_dataloader, epoch_num=5):\n",
    "#         \"\"\"\n",
    "#         Train function\n",
    "#         Args:\n",
    "#             train_dataloader: dataloader for training\n",
    "#             val_dataloader: dataloader for validation\n",
    "#             epoch_num: number of epoch for training and validation\n",
    "#         \"\"\"\n",
    "#         start = datetime.datetime.now()\n",
    "#         print(\"start time\", start.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "#\n",
    "#         for epoch in range(epoch_num):\n",
    "#             # Train\n",
    "#             train_loss = self._train_epoch(train_dataloader)\n",
    "#             self.train_history_epochs.append(train_loss)\n",
    "#             if self.verbose:\n",
    "#                 print(f'Epoch {epoch} of {epoch_num - 1}, train loss: {train_loss:.5f}')\n",
    "#                 now = datetime.datetime.now()\n",
    "#                 print(\"Epoch end time\", now.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "#             torch.cuda.empty_cache()\n",
    "#\n",
    "#             # Validation\n",
    "#             val_loss = self._val_epoch(val_dataloader)\n",
    "#             self.val_history_epochs.append(val_loss)\n",
    "#             if self.verbose:\n",
    "#                 print(f'Epoch {epoch} of {epoch_num - 1}, val loss: {val_loss:.5f}')\n",
    "#                 now = datetime.datetime.now()\n",
    "#                 print(\"Epoch end time\", now.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "#             torch.cuda.empty_cache()\n",
    "#\n",
    "#             # Save\n",
    "#             if self.save_step == 0 or self.save_directory == \"\":\n",
    "#                 continue\n",
    "#             if (epoch + 1) % self.save_step == 0:\n",
    "#                 save_model(self.model.to('cpu'), path=f\"{self.save_directory}\\\\epoch_{self._epoch_string(epoch, epoch_num)}.pt\")\n",
    "#\n",
    "#         now = datetime.datetime.now()\n",
    "#         print(\"end time\", now.strftime(\"%d-%m-%Y %H:%M\"))\n",
    "#         print(\"delta\", now - start)\n",
    "#\n",
    "#     def _train_epoch(self, train_dataloader):\n",
    "#         \"\"\"\n",
    "#         Method for epoch training\n",
    "#         Args:\n",
    "#             train_dataloader:  train dataloader\n",
    "#\n",
    "#         Returns: train loss\n",
    "#\n",
    "#         \"\"\"\n",
    "#         self.model = self.model.to(self.device)\n",
    "#\n",
    "#         train_running_loss = 0.0\n",
    "#         self.model.train()\n",
    "#         for data, mask, targets in tqdm(train_dataloader):\n",
    "#             data = data.to(self.device)\n",
    "#             mask = mask.to(self.device)\n",
    "#             targets = targets.to(self.device)\n",
    "#             outputs = self.model(data)\n",
    "#\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss = self.criterion(outputs, mask, targets)\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             loss_number = loss.item()\n",
    "#             train_running_loss += loss_number\n",
    "#             self.train_history_batches.append(loss_number)\n",
    "#\n",
    "#         train_loss = train_running_loss / len(train_dataloader)\n",
    "#         return train_loss\n",
    "#\n",
    "#     def _val_epoch(self, val_dataloader):\n",
    "#         \"\"\"\n",
    "#         Method for epoch validation\n",
    "#         Args:\n",
    "#             val_dataloader:\n",
    "#\n",
    "#         Returns: validation loss\n",
    "#\n",
    "#         \"\"\"\n",
    "#         val_running_loss = 0.0\n",
    "#         self.model.eval()\n",
    "#         for data, mask, targets in tqdm(val_dataloader):\n",
    "#             data = data.to(self.device)\n",
    "#             mask = mask.to(self.device)\n",
    "#             targets = targets.to(self.device)\n",
    "#             outputs = self.model(data)\n",
    "#\n",
    "#             loss = self.criterion(outputs, mask, targets)\n",
    "#             loss_number = loss.item()\n",
    "#             val_running_loss += loss_number\n",
    "#             self.val_history_batches.append(loss_number)\n",
    "#\n",
    "#         val_loss = val_running_loss / len(val_dataloader)\n",
    "#         return val_loss\n",
    "#\n",
    "#     @staticmethod\n",
    "#     def _epoch_string(epoch, epoch_num):\n",
    "#         \"\"\"\n",
    "#         Method to create a string form of current epoch number, using the same number\n",
    "#         of digits for every training session\n",
    "#\n",
    "#         Args:\n",
    "#             epoch: number of current epoch\n",
    "#             epoch_num: number of epochs for this training session\n",
    "#\n",
    "#         Returns: converted to string epoch number\n",
    "#\n",
    "#         \"\"\"\n",
    "#         num_digits_epoch_num = get_num_digits(epoch_num)\n",
    "#         num_digits_epoch = get_num_digits(epoch)\n",
    "#\n",
    "#         epoch_string = \"0\"*(num_digits_epoch_num - num_digits_epoch) + str(epoch)\n",
    "#         return epoch_string\n",
    "#\n",
    "#     def draw_history_plots(self, epochs=True):\n",
    "#         \"\"\"\n",
    "#         Draws plots of train and validation\n",
    "#\n",
    "#         Args:\n",
    "#             epochs: TODO: if 'True', draws history plots by epochs, else by batches\n",
    "#         \"\"\"\n",
    "#         if epochs:\n",
    "#             plt.plot(self.train_history_epochs, label=\"train\")\n",
    "#             plt.plot(self.val_history_epochs, label=\"val\")\n",
    "#             plt.show()\n",
    "#         else:\n",
    "#             plt.plot(self.train_history_batches, label=\"train\")\n",
    "#             plt.plot(self.val_history_batches, label=\"val\")\n",
    "#             plt.show()\n",
    "#\n",
    "#     def __str__(self):\n",
    "#         description = f\"Model:\\n\\t{str(self.model)}\\n\" \\\n",
    "#                       f\"Criterion: \\n\\t{str(type(self.criterion))}\\n\" \\\n",
    "#                       f\"Optimizer: \\n\\t{str(type(self.optimizer))}\"\n",
    "#         return description"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:24:03.427519700Z",
     "start_time": "2023-05-31T15:24:03.419491700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "trainer = TrainerWithMask(\n",
    "    model_=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    save_directory=save_directory,\n",
    "    save_step=1,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:24:04.068610400Z",
     "start_time": "2023-05-31T15:24:04.060311500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 31-05-2023 18:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/364 [00:00<?, ?it/s]C:\\Users\\DenisovDmitrii\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 364/364 [03:53<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 of 29, train loss: 0.97101\n",
      "Epoch end time 31-05-2023 18:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:30<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 of 29, val loss: 0.82747\n",
      "Epoch end time 31-05-2023 18:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [04:37<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 29, train loss: 0.76919\n",
      "Epoch end time 31-05-2023 18:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:34<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 29, val loss: 0.84557\n",
      "Epoch end time 31-05-2023 18:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [04:38<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 29, train loss: 0.72421\n",
      "Epoch end time 31-05-2023 18:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:29<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 29, val loss: 0.78874\n",
      "Epoch end time 31-05-2023 18:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [05:10<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 29, train loss: 0.69397\n",
      "Epoch end time 31-05-2023 18:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:30<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 29, val loss: 0.72488\n",
      "Epoch end time 31-05-2023 18:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [04:13<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 of 29, train loss: 0.67343\n",
      "Epoch end time 31-05-2023 18:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:28<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 of 29, val loss: 0.94393\n",
      "Epoch end time 31-05-2023 18:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [04:18<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 of 29, train loss: 0.65724\n",
      "Epoch end time 31-05-2023 18:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:29<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 of 29, val loss: 0.73669\n",
      "Epoch end time 31-05-2023 18:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [04:24<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 of 29, train loss: 0.64422\n",
      "Epoch end time 31-05-2023 18:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:30<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 of 29, val loss: 0.67835\n",
      "Epoch end time 31-05-2023 18:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [04:07<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 of 29, train loss: 0.63531\n",
      "Epoch end time 31-05-2023 19:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:27<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 of 29, val loss: 0.69932\n",
      "Epoch end time 31-05-2023 19:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [03:44<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 of 29, train loss: 0.62543\n",
      "Epoch end time 31-05-2023 19:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:29<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 of 29, val loss: 0.68330\n",
      "Epoch end time 31-05-2023 19:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [04:54<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 of 29, train loss: 0.61957\n",
      "Epoch end time 31-05-2023 19:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:29<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 of 29, val loss: 0.72134\n",
      "Epoch end time 31-05-2023 19:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [04:40<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 29, train loss: 0.61270\n",
      "Epoch end time 31-05-2023 19:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:27<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 29, val loss: 0.61780\n",
      "Epoch end time 31-05-2023 19:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [04:07<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 of 29, train loss: 0.60546\n",
      "Epoch end time 31-05-2023 19:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:28<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 of 29, val loss: 0.63200\n",
      "Epoch end time 31-05-2023 19:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [03:06<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 of 29, train loss: 0.59896\n",
      "Epoch end time 31-05-2023 19:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 30/127 [00:13<00:11,  8.11it/s]"
     ]
    }
   ],
   "source": [
    "trainer.train(train_dataloader, val_dataloader, epoch_num=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T17:28:17.380559300Z",
     "start_time": "2023-05-31T15:24:15.850486700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "trainer.draw_history_plots()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "print(str(trainer))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.save_history_plots(save_dir=r\"директория\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# file = open(os.path.join(save_directory, \"readme.txt\"), 'w')\n",
    "# file.write(str(trainer))\n",
    "# file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.create_readme(save_dir=r\"директория\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
